{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2742aa",
   "metadata": {},
   "source": [
    "# 02 - Generating Dataset 1\n",
    "\n",
    "The purpose of this notebook is to create a dataset that will be used for testing the performance of the package and conducting a series of experiments.\n",
    "\n",
    "By separating the creation of the dataset from its use it should be easier to re-use the dataset for the different tests and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532cfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload functions every time\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d258c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# This will add the src directory to sys.path\n",
    "# meaning that the privacy_fingerprint will be found\n",
    "# note it assumes the current working directory is the folder containing this notebook\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir))+'/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e293e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zellaking/Repos/privfp-poc-zk/env-privfp/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from privacy_fingerprint.common.config import (\n",
    "    load_global_config_from_file,\n",
    "    load_experiment_config_from_file,\n",
    "    load_experiment_config,\n",
    ")\n",
    "import privacy_fingerprint.generate.synthea as synthea\n",
    "import privacy_fingerprint.generate.language_model as llm\n",
    "import privacy_fingerprint.extract.aws_comprehend as aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893b018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/pm79dxzs0v70y4gz98dl13440000gn/T/ipykernel_30779/1344694839.py:12: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  load_experiment_config(expt_config.dict())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentConfig(synthea=ExperimentSyntheaConfig(county='Hampshire', encounter_type='Encounter Inpatient', num_records=100, extra_config={}, records_per_patient=1, ethnicity_types=['White - British', 'White - Irish', 'White - Any other White background', 'Mixed - White and Black Caribbean', 'Mixed - White and Black African', 'Mixed - White and Asian', 'Mixed - Any other mixed background', 'Asian or Asian British - Indian', 'Asian or Asian British - Pakistani', 'Asian or Asian British - Bangladeshi', 'Asian or Asian British - Any other Asian background', 'Black or Black British - Caribbean', 'Black or Black British - African', 'Black or Black British - Any other Black background', 'Other Ethnic Groups - Chinese', 'Other Ethnic Groups - Any other ethnic group']), openai=ExperimentOpenAPIConfig(model='text-davinci-003', max_tokens=256, temperature=0.7, prompt='Describe this patient as if you were a medical doctor.'), scoring=ScoringConfig(encoding_scheme='one-hot', max_columns=30))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example config files are available in the config directory.\n",
    "# These files will need to be customised with your API keys.\n",
    "\n",
    "load_global_config_from_file(\"../configs/global_configs.yaml\")\n",
    "load_experiment_config_from_file(\"../configs/experiment_config.yaml\")\n",
    "\n",
    "# Config options can be modified inline. To keep this notebook/experiment small\n",
    "# the number of records will be changed to 10.\n",
    "expt_config = load_experiment_config()\n",
    "# expt_config.synthea.encounter_type = \"Encounter for symptom\"\n",
    "expt_config.synthea.num_records = 100  # 100_000 used to create dataset1\n",
    "load_experiment_config(expt_config.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Encounter Inpatient'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_config.synthea.encounter_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d506cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Synthea output will be saved to a directory\n",
    "output_dir = \"../experiments/02_generate_dataset_inpatients\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "export_directory = os.path.join(output_dir, \"synthea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa65aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-19 10:35:57.405413\n",
      "Encounter Inpatient\n",
      "2023-11-19 10:36:45.115142\n"
     ]
    }
   ],
   "source": [
    "# CAUTION: Given the number of records, running this cell will be extremely slow.\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "# Generate structured records\n",
    "synthea_records = synthea.generate_records(export_directory)\n",
    "\n",
    "with open(os.path.join(output_dir, \"synthea_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(synthea_records, fp)\n",
    "    \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ead513",
   "metadata": {},
   "source": [
    "A modified version of the above was run. This generated 100k records in Synthea but then limited the import of those records to 1000. This then formed our dataset1. The records generated in our run are available separately to this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21da9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"synthea_dataset.json\")) as fp:\n",
    "    synthea_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0738cc8",
   "metadata": {},
   "source": [
    "The structured notes from Synthea can then be converted to free-text clinical notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note_generator = llm.LMGenerator()\n",
    "llm_results = list(clinical_note_generator.generate_text(synthea_records))\n",
    "\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(llm_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e23603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\")) as fp:\n",
    "    llm_results = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbc893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NER step using AWS ComprehendMedical is the most expensive step.\n",
    "# The cost can be estimated with the following function:\n",
    "\n",
    "print(\"Estimated cost is $\", aws.calculate_ner_cost(llm_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_extract = aws.ComprehendExtractor()\n",
    "ner_records = [aws_extract.extract_record(r) for r in llm_results]\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(ner_records, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\")) as fp:\n",
    "    ner_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd1b0f",
   "metadata": {},
   "source": [
    "With the raw NER results generated, experiments will move to individual notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
