{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2742aa",
   "metadata": {},
   "source": [
    "# 02 - Generating Dataset 1\n",
    "\n",
    "The purpose of this notebook is to create a dataset that will be used for testing the performance of the package and conducting a series of experiments.\n",
    "\n",
    "By separating the creation of the dataset from its use it should be easier to re-use the dataset for the different tests and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532cfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload functions every time\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0d258c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# This will add the src directory to sys.path\n",
    "# meaning that the privacy_fingerprint will be found\n",
    "# note it assumes the current working directory is the folder containing this notebook\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir))+'/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e293e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_fingerprint.common.config import (\n",
    "    load_global_config_from_file,\n",
    "    load_experiment_config_from_file,\n",
    "    load_experiment_config,\n",
    ")\n",
    "import privacy_fingerprint.generate.synthea as synthea\n",
    "import privacy_fingerprint.generate.language_model as llm\n",
    "import privacy_fingerprint.extract.aws_comprehend as aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893b018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/pm79dxzs0v70y4gz98dl13440000gn/T/ipykernel_13948/1344694839.py:12: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  load_experiment_config(expt_config.dict())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentConfig(synthea=ExperimentSyntheaConfig(county='Hampshire', encounter_type='Encounter Inpatient', num_records=100, extra_config={}, records_per_patient=1, ethnicity_types=['White - British', 'White - Irish', 'White - Any other White background', 'Mixed - White and Black Caribbean', 'Mixed - White and Black African', 'Mixed - White and Asian', 'Mixed - Any other mixed background', 'Asian or Asian British - Indian', 'Asian or Asian British - Pakistani', 'Asian or Asian British - Bangladeshi', 'Asian or Asian British - Any other Asian background', 'Black or Black British - Caribbean', 'Black or Black British - African', 'Black or Black British - Any other Black background', 'Other Ethnic Groups - Chinese', 'Other Ethnic Groups - Any other ethnic group']), openai=ExperimentOpenAPIConfig(model='text-davinci-003', max_tokens=256, temperature=0.7, prompt='Describe this patient as if you were a medical doctor.'), scoring=ScoringConfig(encoding_scheme='one-hot', max_columns=30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example config files are available in the config directory.\n",
    "# These files will need to be customised with your API keys.\n",
    "\n",
    "load_global_config_from_file(\"../configs/global_configs.yaml\")\n",
    "load_experiment_config_from_file(\"../configs/experiment_config.yaml\")\n",
    "\n",
    "# Config options can be modified inline. To keep this notebook/experiment small\n",
    "# the number of records will be changed to 10.\n",
    "expt_config = load_experiment_config()\n",
    "# expt_config.synthea.encounter_type = \"Encounter for symptom\"\n",
    "expt_config.synthea.num_records = 100  # 100_000 used to create dataset1\n",
    "load_experiment_config(expt_config.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Encounter Inpatient'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_config.synthea.encounter_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d506cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Synthea output will be saved to a directory\n",
    "output_dir = \"../experiments/02_generate_dataset_inpatients_temp\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "export_directory = os.path.join(output_dir, \"synthea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fa65aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-26 17:20:46.666911\n",
      "Encounter Inpatient\n",
      "2023-11-26 17:21:16.892837\n"
     ]
    }
   ],
   "source": [
    "# CAUTION: Given the number of records, running this cell will be extremely slow.\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "# Generate structured records\n",
    "synthea_records = synthea.generate_records(export_directory)\n",
    "\n",
    "with open(os.path.join(output_dir, \"synthea_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(synthea_records, fp)\n",
    "    \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of inpatient encounters found in the generate records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synthea_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ead513",
   "metadata": {},
   "source": [
    "A modified version of the above was run. This generated 100k records in Synthea but then limited the import of those records to 1000. This then formed our dataset1. The records generated in our run are available separately to this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21da9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"synthea_dataset.json\")) as fp:\n",
    "    synthea_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0738cc8",
   "metadata": {},
   "source": [
    "The structured notes from Synthea can then be converted to free-text clinical notes.\n",
    "\n",
    "If this fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69eacff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/zellaking/Repos/privfp-poc-zk/notebooks/02_generate_dataset.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zellaking/Repos/privfp-poc-zk/notebooks/02_generate_dataset.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clinical_note_generator \u001b[39m=\u001b[39m llm\u001b[39m.\u001b[39mLMGenerator()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zellaking/Repos/privfp-poc-zk/notebooks/02_generate_dataset.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m llm_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(clinical_note_generator\u001b[39m.\u001b[39;49mgenerate_text(synthea_records))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zellaking/Repos/privfp-poc-zk/notebooks/02_generate_dataset.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39m\"\u001b[39m\u001b[39mllm_dataset.json\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zellaking/Repos/privfp-poc-zk/notebooks/02_generate_dataset.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(llm_results, fp)\n",
      "File \u001b[0;32m~/Repos/privfp-poc-zk/src/privacy_fingerprint/generate/language_model.py:56\u001b[0m, in \u001b[0;36mLMGenerator.generate_text\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m     54\u001b[0m     batch \u001b[39m=\u001b[39m []\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_query_api(batch)\n\u001b[1;32m     57\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecords_from_cache(records)\n",
      "File \u001b[0;32m~/Repos/privfp-poc-zk/src/privacy_fingerprint/generate/language_model.py:70\u001b[0m, in \u001b[0;36mLMGenerator.batch_query_api\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mwhile\u001b[39;00m attempts \u001b[39m<\u001b[39m config\u001b[39m.\u001b[39mopenai\u001b[39m.\u001b[39mretry_attempts:\n\u001b[1;32m     69\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m         api_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_api(query))\n\u001b[1;32m     71\u001b[0m         \u001b[39mwith\u001b[39;00m get_session()() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m     72\u001b[0m             \u001b[39mfor\u001b[39;00m record, result \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(batch, api_results):\n",
      "File \u001b[0;32m~/Repos/privfp-poc-zk/src/privacy_fingerprint/generate/language_model.py:112\u001b[0m, in \u001b[0;36mLMGenerator._call_api\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m# openai.api_key = config.openai.api_key\u001b[39;00m\n\u001b[1;32m    111\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m openai_result \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    113\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    114\u001b[0m     prompt\u001b[39m=\u001b[39;49mquery,\n\u001b[1;32m    115\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_tokens,\n\u001b[1;32m    116\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemperature,\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    118\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m openai_result\u001b[39m.\u001b[39mchoices:\n\u001b[1;32m    119\u001b[0m     \u001b[39myield\u001b[39;00m result\u001b[39m.\u001b[39mtext\n",
      "File \u001b[0;32m~/Repos/privfp-poc-zk/env-privfp/lib/python3.11/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Repos/privfp-poc-zk/env-privfp/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:151\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[1;32m    143\u001b[0m         timeout,\n\u001b[1;32m    144\u001b[0m         stream,\n\u001b[1;32m    145\u001b[0m         headers,\n\u001b[1;32m    146\u001b[0m         request_timeout,\n\u001b[1;32m    147\u001b[0m         typed_api_type,\n\u001b[1;32m    148\u001b[0m         requestor,\n\u001b[1;32m    149\u001b[0m         url,\n\u001b[1;32m    150\u001b[0m         params,\n\u001b[0;32m--> 151\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/privfp-poc-zk/env-privfp/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:108\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    106\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 108\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    109\u001b[0m     api_key,\n\u001b[1;32m    110\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    111\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    112\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    113\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[1;32m    116\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    117\u001b[0m     deployment_id,\n\u001b[1;32m    118\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m     params,\n\u001b[1;32m    127\u001b[0m )\n",
      "File \u001b[0;32m~/Repos/privfp-poc-zk/env-privfp/lib/python3.11/site-packages/openai/api_requestor.py:139\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    132\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     organization\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m    140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m    141\u001b[0m         ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m    142\u001b[0m         \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m    143\u001b[0m         \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m api_version \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_version\n",
      "File \u001b[0;32m~/Repos/privfp-poc-zk/env-privfp/lib/python3.11/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mapi_key\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
     ]
    }
   ],
   "source": [
    "clinical_note_generator = llm.LMGenerator()\n",
    "llm_results = list(clinical_note_generator.generate_text(synthea_records))\n",
    "\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(llm_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e23603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\")) as fp:\n",
    "    llm_results = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbc893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NER step using AWS ComprehendMedical is the most expensive step.\n",
    "# The cost can be estimated with the following function:\n",
    "\n",
    "print(\"Estimated cost is $\", aws.calculate_ner_cost(llm_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_extract = aws.ComprehendExtractor()\n",
    "ner_records = [aws_extract.extract_record(r) for r in llm_results]\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(ner_records, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\")) as fp:\n",
    "    ner_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd1b0f",
   "metadata": {},
   "source": [
    "With the raw NER results generated, experiments will move to individual notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
